
seed: 1234
logging_level: INFO

debug: False

tensor_parallel_size: 1

environ:
  model_cache: HF_MODEL_CACHE
  dataset_cache: HF_DATASETS_CACHE
  openai_api_key: OPENAI_API_KEY
  dummy_api_key: DUMMY_API_KEY

model:
  name: meta-llama/Llama-3.1-8B-Instruct
  is_api: False
  base_url: http://localhost:8000/v1

path: 
  output: /home/heyjoonkim/data/reasoning_abstention
  # output: /data1/heyjoonkim/reasoning_abstention

dataset:
  # select from : heyjoonkim/hendrycks_math, heyjoonkim/math_500
  name: heyjoonkim/hendrycks_math

generation:
  template_id: 0
  num_generations: 1
  num_demonstrations: 2
  # num_demonstrations: 4
  max_new_tokens: 3000
  temperature: 0.0
  top_p: 1.0
  top_logprobs: 100

uncertainty:
  num_generations: 5
  temperature: 0.3
  validation_model: Qwen/Qwen2.5-7B-Instruct


error_propagation:
  num_generations: 5
  temperature: 0.7
  openai:
    model: o4-mini