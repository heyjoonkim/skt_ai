seed: 1234
logging_level: INFO

debug: False

tensor_parallel_size: 1

environ:
  model_cache: HF_MODEL_CACHE
  dataset_cache: HF_DATASETS_CACHE
  openai_api_key: OPENAI_API_KEY
  dummy_api_key: DUMMY_API_KEY

model:
  name: meta-llama/Llama-3.2-1B-Instruct

path: 
  output: /home/heyjoonkim/data/skt_ai

dataset:
  # select from : heyjoonkim/hendrycks_math, heyjoonkim/math_500
  train: ../data/train.jsonl
  test: heyjoonkim/math_500

generation:
  template_id: 0
  num_generations: 1
  num_demonstrations: 2
  # num_demonstrations: 4
  max_new_tokens: 3000
  temperature: 0.0
  top_p: 1.0
  top_logprobs: 100



    
training:
  # num_training_epochs: 1
  num_training_epochs: 0
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 2
  learning_rate: 1e-3

  test_dataset: heyjoonkim/math_500