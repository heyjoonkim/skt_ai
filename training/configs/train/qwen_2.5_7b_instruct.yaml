
seed: 1234
logging_level: INFO

debug: False

tensor_parallel_size: 1

environ:
  model_cache: HF_MODEL_CACHE
  dataset_cache: HF_DATASETS_CACHE
  openai_api_key: OPENAI_API_KEY
  dummy_api_key: DUMMY_API_KEY

model:
  name: Qwen/Qwen2.5-7B-Instruct
  is_api: False
  base_url: http://localhost:8000/v1

path: 
  output: /home/heyjoonkim/data/reasoning_abstention
  # output: /data1/heyjoonkim/reasoning_abstention

dataset:
  # select from : heyjoonkim/hendrycks_math, heyjoonkim/math_500
  train: heyjoonkim/hendrycks_math
  test: heyjoonkim/math_500

generation:
  template_id: 0
  num_generations: 1
  num_demonstrations: 2
  # num_demonstrations: 4
  max_new_tokens: 3000
  temperature: 0.0
  top_p: 1.0
  top_logprobs: 100

build_dataset:
  test_size: 0.1

error_propagation:
  # dataset: heyjoonkim/hendrycks_math
  dataset: heyjoonkim/math_500
  # 동일한 숫자의 step만 비교하기 위해 사용
  num_steps: 5

  # trajectory 샘플링해서 생성할 때 사용
  num_generations: 30
  temperature: 0.6
  top_p: 0.95
  max_new_tokens: 800
  max_sampling_per_step: 100

  verbal_confidence_threshold: 90
  
  openai:
    model: o4-mini

    
training:
  # num_training_epochs: 1
  num_training_epochs: 1
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 4
  learning_rate: 1e-3
  use_qlora: False
  # for DPO training
  beta: 0.1
  # for RPO (DPO + SFT)
  rpo_alpha: null

  # for LoRA
  lora:
    r: 8
    alpha: 16

test:
  validation_dataset: heyjoonkim/hendrycks_math
  test_dataset: heyjoonkim/math_500

  # test or validation
  is_test: False

  # for subset (pos or neg)
  split: pos

  # balance number of pos and neg
  is_balanced: True